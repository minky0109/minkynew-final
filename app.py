import streamlit as st
import fitz
import re
import requests
from io import BytesIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #F8F4FF; }
    h1, h2, h3 { color: #6F42C1 !important; }
    div.stButton > button { background-color: #6F42C1; color: white; border-radius: 10px; font-weight: bold; height: 3.5em; border: none; }
    div.stButton > button:hover { background-color: #5A32A3; color: white; }
    .compare-box { border: 2px solid #E0D4F7; padding: 20px; border-radius: 15px; background-color: white; line-height: 1.8; overflow-wrap: break-word; min-height: 200px; }
    mark { background-color: #E6E0FF; color: #5A32A3; font-weight: bold; border-radius: 3px; padding: 0 2px; }
    </style>
    """, unsafe_allow_html=True)

# --- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë‹¤ìš´ë¡œë“œ ë§í¬ ë³€í™˜ ---
def get_gdrive_direct_link(url):
    file_id = ""
    patterns = [r'/d/([a-zA-Z0-9_-]+)', r'id=([a-zA-Z0-9_-]+)', r'srcid=([a-zA-Z0-9_-]+)']
    for p in patterns:
        match = re.search(p, url)
        if match:
            file_id = match.group(1)
            break
    return f'https://drive.google.com/uc?export=download&id={file_id}' if file_id else url

# --- í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¬¸í•­ ë¶„ë³„ ---
def extract_problems_refined(content, filename):
    try:
        doc = fitz.open(stream=content, filetype="pdf")
        all_problems = []
        skip_keywords = ['í•™ë…„ë„', 'ì˜ì—­', 'í™•ì¸ì‚¬í•­', 'ìœ ì˜ì‚¬í•­', 'ì„±ëª…', 'ìˆ˜í—˜ë²ˆí˜¸', 'ë¬¸ì œì§€', 'íƒêµ¬']

        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            lines = page.get_text("text").split('\n')
            current_prob, current_num = "", ""

            for line in lines:
                cleaned = line.strip()
                if not cleaned or len(cleaned) < 2: continue
                if any(kw in cleaned for kw in skip_keywords): continue

                num_match = re.match(r'^(\d+[\.|\)]|\[\d+\])', cleaned)
                if num_match:
                    if current_prob and len(current_prob) > 30:
                        all_problems.append({"text": current_prob, "page": page_num + 1, "num": current_num if current_num else "ë¯¸ìƒ", "source": filename})
                    current_num, current_prob = num_match.group(1).strip(), cleaned
                else:
                    if current_prob: current_prob += " " + cleaned
            
            if current_prob and len(current_prob) > 30:
                all_problems.append({"text": current_prob, "page": page_num + 1, "num": current_num if current_num else "ë¯¸ìƒ", "source": filename})
        return all_problems
    except: return []

# --- ìœ ì‚¬ë„ ì‚°ì¶œ ---
def calculate_sim(t1, t2):
    v = TfidfVectorizer(ngram_range=(2, 4), analyzer='char')
    try:
        tfidf = v.fit_transform([t1, t2])
        return cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
    except: return 0

# --- [í•µì‹¬ ì¶”ê°€] í•˜ì´ë¼ì´íŒ… ë¡œì§ ---
def highlight_overlap(target, reference):
    if not target or not reference: return target
    
    # ê³µë°± ì œê±° í›„ ë¹„êµë¥¼ ìœ„í•´ ì •ê·œí™”
    ref_clean = re.sub(r'\s+', '', reference)
    
    # 6ê¸€ìì”© ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ê²¹ì¹˜ëŠ” êµ¬ê°„ íƒìƒ‰
    min_len = 6
    to_highlight = []
    for i in range(len(target) - min_len + 1):
        chunk = target[i:i+min_len]
        if len(chunk.strip()) < min_len: continue
        if re.sub(r'\s+', '', chunk) in ref_clean:
            to_highlight.append(chunk)
    
    # ê²¹ì¹˜ëŠ” êµ¬ê°„ë“¤ì„ ë³‘í•©í•˜ì—¬ mark íƒœê·¸ ì‚½ì…
    sorted_chunks = sorted(list(set(to_highlight)), key=len, reverse=True)
    result = target
    for chunk in sorted_chunks:
        if chunk in result:
            result = result.replace(chunk, f"[[MS]]{chunk}[[ME]]")
    
    # ì¤‘ë³µ íƒœê·¸ ì •ë¦¬ ë° ì¹˜í™˜
    result = result.replace("[[MS]]", "<mark>").replace("[[ME]]", "</mark>")
    result = re.sub(r'(</mark>\s*<mark>)', '', result)
    return result

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸŸ£ ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°")

default_links = """ëª¨í‰_ìˆ˜ëŠ¥, https://drive.google.com/file/d/1kf1dZDTFCfAHM9OSAwqaAXI62ClJ3J-S/view?usp=drive_link
2026 ìˆ˜íŠ¹ ìƒìœ¤, https://drive.google.com/file/d/1xlcMNaNQIbzA1iLXB9lD6eNYL5LM4_LJ/view?usp=drive_link"""

with st.sidebar:
    st.header("ğŸ”— ê¸°ì¤€ DB ë“±ë¡")
    links_input = st.text_area("ì´ë¦„, êµ¬ê¸€ë§í¬", value=default_links, height=150)

uploaded_file = st.file_uploader("ğŸ“ ë¶„ì„í•  ë¬¸í•­ PDF ì—…ë¡œë“œ", type="pdf")

if uploaded_file and links_input:
    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ë° í•˜ì´ë¼ì´íŒ… ì‹œì‘"):
        final_results = []
        all_ref_problems = []
        
        # 1. DB ë¡œë“œ
        lines = [line for line in links_input.split('\n') if ',' in line]
        for line in lines:
            name, url = line.split(',', 1)
            direct_url = get_gdrive_direct_link(url.strip())
            try:
                res = requests.get(direct_url, timeout=30)
                if res.status_code == 200:
                    all_ref_problems.extend(extract_problems_refined(res.content, name.strip()))
            except: pass

        # 2. ì—…ë¡œë“œ íŒŒì¼ ë¡œë“œ
        target_probs = extract_problems_refined(uploaded_file.read(), "ì—…ë¡œë“œ")

        # 3. ë¶„ì„
        if all_ref_problems and target_probs:
            prog = st.progress(0)
            status = st.empty()
            for i, target in enumerate(target_probs):
                t_num = target.get('num', 'ë¯¸ìƒ')
                status.text(f"ğŸ” {i+1}ë²ˆ({t_num}) ë¬¸í•­ ë¶„ì„ ì¤‘...")
                best_score, best_match = 0, None
                for ref in all_ref_problems:
                    score = calculate_sim(target['text'], ref['text'])
                    if score > best_score:
                        best_score, best_match = score, ref
                
                final_results.append({
                    "id": i + 1, "target": target.get('text', ''), "num": t_num,
                    "score": round(best_score*100, 1), "match": best_match
                })
                prog.progress((i + 1) / len(target_probs))
            st.session_state['results'] = final_results
            status.success("âœ… ì •ë°€ ë¶„ì„ ì™„ë£Œ!")

# --- ê²°ê³¼ í‘œì‹œ ---
if 'results' in st.session_state:
    st.markdown("---")
    for res in st.session_state['results']:
        score = res.get('score', 0)
        num = res.get('num', 'ë¯¸ìƒ')
        color = "ğŸ”´" if score > 65 else "ğŸŸ¡" if score > 35 else "ğŸŸ¢"
        match = res.get('match')
        
        info = f" - [ë§¤ì¹­: {match['source']} {match['page']}p {match['num']}]" if match else ""
        label = f"{color} {num}ë²ˆ (ìœ ì‚¬ë„ {score}%){info}"

        with st.expander(label):
            c1, c2 = st.columns(2)
            if match:
                # í•˜ì´ë¼ì´íŒ… ì ìš©
                h_target = highlight_overlap(res['target'], match['text'])
                h_match = highlight_overlap(match['text'], res['target'])
                
                with c1: st.markdown(f"<div class='compare-box'><b>[ëŒ€ìƒ ë¬¸í•­]</b><hr>{h_target}</div>", unsafe_allow_html=True)
                with c2: st.markdown(f"<div class='compare-box'><b>[DB ë¬¸í•­]</b><hr>{h_match}</div>", unsafe_allow_html=True)
            else:
                with c1: st.markdown(f"<div class='compare-box'><b>[ëŒ€ìƒ ë¬¸í•­]</b><hr>{res['target']}</div>", unsafe_allow_html=True)
                with c2: st.info("ë§¤ì¹­ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
