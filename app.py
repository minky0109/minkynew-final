import streamlit as st
import fitz
import re
import requests
from io import BytesIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #F8F4FF; }
    h1, h2, h3 { color: #6F42C1 !important; }
    div.stButton > button { background-color: #6F42C1; color: white; border-radius: 10px; font-weight: bold; height: 3.5em; width: 100%; }
    .compare-box { border: 2px solid #E0D4F7; padding: 20px; border-radius: 15px; background-color: white; line-height: 1.8; min-height: 150px; }
    mark { background-color: #E6E0FF; color: #5A32A3; font-weight: bold; padding: 0 2px; }
    </style>
    """, unsafe_allow_html=True)

# --- êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬ ë³€í™˜ ---
def get_gdrive_direct_link(url):
    file_id = ""
    patterns = [r'/d/([a-zA-Z0-9_-]+)', r'id=([a-zA-Z0-9_-]+)', r'srcid=([a-zA-Z0-9_-]+)']
    for p in patterns:
        match = re.search(p, url)
        if match:
            file_id = match.group(1); break
    return f'https://drive.google.com/uc?export=download&id={file_id}' if file_id else url

# --- [ì •ë°€ë„ ìµœì í™”] ë¬¸í•­ ë¶„ë¥˜ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ---
def extract_problems_refined(content, filename):
    try:
        doc = fitz.open(stream=content, filetype="pdf")
        all_problems = []
        # ì œì™¸í•  ë…¸ì´ì¦ˆ í‚¤ì›Œë“œ ê°•í™”
        skip_keywords = ['í•™ë…„ë„', 'ì˜ì—­', 'í™•ì¸ì‚¬í•­', 'ìœ ì˜ì‚¬í•­', 'ì„±ëª…', 'ìˆ˜í—˜ë²ˆí˜¸', 'ë¬¸ì œì§€', 'íƒêµ¬', 'ì‚¬íšŒÂ·ë¬¸í™”', 'ìƒí™œê³¼ ìœ¤ë¦¬', 'ìª½', 'êµì¬']
        
        current_prob_text = ""
        current_num = ""
        current_page = 1

        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            # ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ ì½ê¸° ìˆœì„œê°€ ë’¤ì„ì´ëŠ” í˜„ìƒ ë°©ì§€
            blocks = page.get_text("blocks", sort=True)
            
            for block in blocks:
                line_text = block[4].replace('\n', ' ').strip()
                if not line_text or len(line_text) < 2: continue
                if any(kw in line_text for kw in skip_keywords): continue

                # [ë¬¸í•­ ë²ˆí˜¸ íŒë³„ ì •ê·œì‹ ê°•í™”]
                # 1. '1.', '20.' ë“± ìˆ«ì+ë§ˆì¹¨í‘œ
                # 2. '[1]', '[20]' ë“± ëŒ€ê´„í˜¸ ìˆ«ì
                # 3. '1)', '20)' ë“± ìˆ«ì+ë‹«ëŠ”ê´„í˜¸
                # ë‹¨, ì„ ì§€ ë²ˆí˜¸(â‘ ~â‘¤)ë‚˜ ë‹¨ìˆœ ë‚ ì§œì™€ í˜¼ë™ë˜ì§€ ì•Šë„ë¡ ì¤„ì˜ ì‹œì‘ë¶€ë¶„ì—ì„œë§Œ ì°¾ìŒ
                num_match = re.match(r'^(\d{1,2}[\.|\)]|\[\d{1,2}\])', line_text)
                
                # ë¬¸í•­ ë²ˆí˜¸ê°€ ìƒˆë¡œ ë°œê²¬ëœ ê²½ìš°
                if num_match:
                    # ê¸°ì¡´ì— ìˆ˜ì§‘í•˜ë˜ ë¬¸í•­ì´ ìˆë‹¤ë©´ ì €ì¥
                    if current_prob_text.strip():
                        all_problems.append({
                            "text": re.sub(r'\s+', ' ', current_prob_text).strip(),
                            "page": current_page,
                            "num": current_num if current_num else "ë¯¸ìƒ",
                            "source": filename
                        })
                    
                    # ìƒˆ ë¬¸í•­ ë°ì´í„° ì´ˆê¸°í™”
                    current_num = num_match.group(1).strip()
                    current_prob_text = line_text
                    current_page = page_num + 1
                else:
                    # ë¬¸í•­ ë²ˆí˜¸ê°€ ì•„ë‹ˆë©´ í˜„ì¬ ìˆ˜ì§‘ ì¤‘ì¸ ë¬¸í•­ ë³¸ë¬¸ì— í•©ì¹¨
                    if current_prob_text:
                        current_prob_text += " " + line_text
                    else:
                        # ë¬¸ì„œ ë§¨ ì²˜ìŒì— ë²ˆí˜¸ ì—†ì´ í…ìŠ¤íŠ¸ê°€ ì‹œì‘ë  ê²½ìš°
                        current_prob_text = line_text
                        current_page = page_num + 1

        # ë£¨í”„ ì¢…ë£Œ í›„ ë§ˆì§€ë§‰ ë¬¸í•­ ì €ì¥
        if current_prob_text.strip():
            all_problems.append({
                "text": re.sub(r'\s+', ' ', current_prob_text).strip(),
                "page": current_page,
                "num": current_num if current_num else "ë§ˆì§€ë§‰",
                "source": filename
            })
            
        return all_problems
    except:
        return []

# --- í•˜ì´ë¼ì´íŒ… ë° ë¶„ì„ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def highlight_overlap(target, reference):
    if not target or not reference: return target
    ref_clean = re.sub(r'\s+', '', reference)
    min_len = 6
    to_highlight = []
    for i in range(len(target) - min_len + 1):
        chunk = target[i:i+min_len]
        if len(chunk.strip()) < min_len: continue
        if re.sub(r'\s+', '', chunk) in ref_clean: to_highlight.append(chunk)
    sorted_chunks = sorted(list(set(to_highlight)), key=len, reverse=True)
    result = target
    for chunk in sorted_chunks:
        if chunk in result: result = result.replace(chunk, f"[[MS]]{chunk}[[ME]]")
    return result.replace("[[MS]]", "<mark>").replace("[[ME]]", "</mark>").replace("</mark><mark>", "")

# --- ë©”ì¸ ë ˆì´ì•„ì›ƒ ë° ì‹¤í–‰ ---
st.title("ğŸŸ£ ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°")

default_links = """ëª¨í‰_ìˆ˜ëŠ¥, https://drive.google.com/file/d/1kf1dZDTFCfAHM9OSAwqaAXI62ClJ3J-S/view?usp=drive_link
2026 ìˆ˜íŠ¹ ìƒìœ¤, https://drive.google.com/file/d/1xlcMNaNQIbzA1iLXB9lD6eNYL5LM4_LJ/view?usp=drive_link
ì‚¬ë¬¸_ëª¨í‰, https://drive.google.com/file/d/1QTIRXZdqlixqhLlUsywqGHZcrxdqZ_mN/view?usp=sharing
2026 ì‚¬ë¬¸_ìˆ˜íŠ¹, https://drive.google.com/file/d/1V-WjvOsOSZwuuRaRObwPqdD07Rvuyx7f/view?usp=drive_link"""

with st.sidebar:
    st.header("ğŸ”— ê¸°ì¤€ DB ì„¤ì •")
    links_input = st.text_area("ì´ë¦„, êµ¬ê¸€ë§í¬", value=default_links, height=200)
    if st.button("ğŸ”„ ê²°ê³¼ ì´ˆê¸°í™”"):
        if 'results' in st.session_state: del st.session_state['results']
        st.rerun()

uploaded_file = st.file_uploader("ğŸ“ ë¶„ì„í•  ëŒ€ìƒ PDF ì—…ë¡œë“œ", type="pdf")

if uploaded_file and links_input:
    if st.button("ğŸš€ ì •ë°€ ë¶„ì„ ì‹œì‘"):
        final_results = []
        all_ref_problems = []
        
        with st.spinner("ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ëŒ€ì¡°í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
            session = requests.Session()
            lines = [l for l in links_input.split('\n') if ',' in l]
            for line in lines:
                name, url = line.split(',', 1)
                direct_url = get_gdrive_direct_link(url.strip())
                try:
                    res = session.get(direct_url, timeout=60)
                    if res.status_code == 200:
                        all_ref_problems.extend(extract_problems_refined(res.content, name.strip()))
                except: pass

            target_probs = extract_problems_refined(uploaded_file.read(), "ì—…ë¡œë“œ")
            
            if all_ref_problems and target_probs:
                prog_bar = st.progress(0)
                vectorizer = TfidfVectorizer(ngram_range=(2, 4), analyzer='char')
                for i, target in enumerate(target_probs):
                    best_score, best_match = 0, None
                    for ref in all_ref_problems:
                        try:
                            tfidf = vectorizer.fit_transform([target['text'], ref['text']])
                            score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
                            if score > best_score:
                                best_score, best_match = score, ref
                        except: continue
                    final_results.append({
                        "id": i+1, "target": target['text'], "num": target['num'], 
                        "score": round(best_score*100, 1), "match": best_match
                    })
                    prog_bar.progress((i + 1) / len(target_probs))
                
                st.session_state['results'] = final_results
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ì´ {len(target_probs)}ê°œ ë¬¸í•­ì´ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("ë¬¸í•­ì„ ì œëŒ€ë¡œ ì½ì–´ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. PDF í˜•ì‹ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

# ê²°ê³¼ í‘œì‹œ ì˜ì—­
if 'results' in st.session_state:
    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸")
    for res in st.session_state['results']:
        score, match, num = res['score'], res['match'], res['num']
        color = "ğŸ”´" if score > 65 else "ğŸŸ¡" if score > 35 else "ğŸŸ¢"
        status = "ìœ„í—˜" if score > 65 else "ì£¼ì˜" if score > 35 else "ì•ˆì „"
        match_info = f" | [ë§¤ì¹­: {match['source']} {match['page']}p {match['num']}]" if match else " | ë§¤ì¹­ ë°ì´í„° ì—†ìŒ"
        
        with st.expander(f"{color} {status} ({score}%) - {num}ë²ˆ ë¬¸í•­ {match_info}"):
            c1, c2 = st.columns(2)
            if match:
                h_target = highlight_overlap(res['target'], match['text'])
                h_match = highlight_overlap(match['text'], res['target'])
                with c1: st.markdown(f"**[ë‚´ ë¬¸í•­]**<div class='compare-box'>{h_target}</div>", unsafe_allow_html=True)
                with c2: st.markdown(f"**[DB ë¬¸í•­]**<div class='compare-box'>{h_match}</div>", unsafe_allow_html=True)
            else:
                with c1: st.markdown(f"**[ë‚´ ë¬¸í•­]**<div class='compare-box'>{res['target']}</div>", unsafe_allow_html=True)
                with c2: st.info("ìœ ì‚¬í•œ ë¬¸í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
