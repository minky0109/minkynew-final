import streamlit as st
import fitz
import re
import requests
from io import BytesIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. í˜ì´ì§€ ì„¤ì • ë° ë³´ë¼ìƒ‰ ë””ìì¸ (ë™ì¼)
st.set_page_config(page_title="ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸°", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #F8F4FF; }
    h1, h2, h3 { color: #6F42C1 !important; }
    div.stButton > button { background-color: #6F42C1; color: white; border-radius: 10px; font-weight: bold; }
    .compare-box { border: 2px solid #E0D4F7; padding: 20px; border-radius: 15px; background-color: white; min-height: 250px; line-height: 1.8; }
    mark { background-color: #E6E0FF; color: #5A32A3; font-weight: bold; border-radius: 3px; }
    </style>
    """, unsafe_allow_html=True)

# --- [í•µì‹¬] êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬ë¥¼ ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë§í¬ë¡œ ë³€í™˜ ---
def get_gdrive_direct_link(url):
    # ê³µìœ  ë§í¬ì—ì„œ ID ì¶”ì¶œ
    file_id = ""
    if 'docs.google.com' in url:
        match = re.search(r'/d/([^/]+)', url)
        if match: file_id = match.group(1)
    elif 'drive.google.com' in url:
        match = re.search(r'id=([^&]+)', url)
        if match: file_id = match.group(1)
    
    if file_id:
        return f'https://drive.google.com/uc?export=download&id={file_id}'
    return url

# --- PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜ (ë°”ì´íŠ¸ ë°ì´í„° ì§€ì›) ---
def extract_problems_from_bytes(content, filename):
    doc = fitz.open(stream=content, filetype="pdf")
    all_problems = []
    noise_keywords = ['í•™ë…„ë„', 'ì˜ì—­', 'í™•ì¸ì‚¬í•­', 'ìœ ì˜ì‚¬í•­', 'ì„±ëª…', 'ìˆ˜í—˜ë²ˆí˜¸']

    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        lines = page.get_text("text").split('\n')
        current_prob, current_num = "", ""
        for line in lines:
            cleaned_line = line.strip()
            if not cleaned_line: continue
            match = re.match(r'^(\d+[\.|\)]|\[\d+\])', cleaned_line)
            if match:
                if current_prob and len(current_prob) >= 40:
                    if not any(nk in current_prob[:30] for nk in noise_keywords):
                        all_problems.append({"text": current_prob, "page": page_num + 1, "num": current_num, "source": filename})
                current_num, current_prob = match.group(1).strip(), cleaned_line
            else:
                current_prob = (current_prob + " " + cleaned_line) if current_prob else cleaned_line
        if current_prob and len(current_prob) >= 40:
            all_problems.append({"text": current_prob, "page": page_num + 1, "num": current_num, "source": filename})
    return all_problems

# --- ìœ ì‚¬ë„ ë° í•˜ì´ë¼ì´íŠ¸ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def calculate_custom_similarity(text1, text2):
    vectorizer = TfidfVectorizer(ngram_range=(2, 4), analyzer='char')
    try:
        tfidf = vectorizer.fit_transform([text1, text2])
        v_score = cosine_similarity(tfidf[0:1], tfidf[1:2])[0][0]
    except: v_score = 0
    s1, s2 = re.sub(r'\s+', '', text1), re.sub(r'\s+', '', text2)
    common_len = sum(1 for i in range(len(s1)-5) if s1[i:i+5] in s2)
    ratio_score = (common_len * 1.5) / max(len(s1), 1)
    return min(round(((v_score * 0.4) + (ratio_score * 0.6)) * 100, 1), 100.0)

def highlight_selective(target, reference):
    ref_stripped = re.sub(r'\s+', '', reference)
    to_highlight = [target[i:i+6] for i in range(len(target)-5) if re.sub(r'\s+', '', target[i:i+6]) in ref_stripped]
    result = target
    for chunk in sorted(list(set(to_highlight)), key=len, reverse=True):
        if chunk in result: result = result.replace(chunk, f"[[MS]]{chunk}[[ME]]")
    return result.replace("[[MS]]", "<mark>").replace("[[ME]]", "</mark>").replace("</mark><mark>", "")

# --- UI ë ˆì´ì•„ì›ƒ ---
st.title("ğŸŸ£ ë¬¸í•­ ìœ ì‚¬ë„ ë¶„ì„ê¸° (Drive ì—°ë™)")

# ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ì¤€ PDF ë§í¬ ê´€ë¦¬
with st.sidebar:
    st.header("ğŸ”— ê¸°ì¤€ PDF ë§í¬ ë“±ë¡")
    st.info("êµ¬ê¸€ ë“œë¼ì´ë¸Œ 'ë§í¬ê°€ ìˆëŠ” ëª¨ë“  ì‚¬ìš©ìì—ê²Œ ê³µê°œ' íŒŒì¼ì„ ë“±ë¡í•˜ì„¸ìš”.")
    
    # ì—¬ëŸ¬ ê°œì˜ ë§í¬ë¥¼ ë„£ì„ ìˆ˜ ìˆë„ë¡ ì„¤ì • (ì˜ˆì‹œ ë°ì´í„° í¬í•¨)
    links_input = st.text_area("íŒŒì¼ ì´ë¦„, ë“œë¼ì´ë¸Œ ì£¼ì†Œ (í•œ ì¤„ì— í•˜ë‚˜ì”©)", 
                               placeholder="ìˆ˜íŠ¹_ìƒìœ¤, https://drive.google.com/...",
                               height=200)

# ë¶„ì„ ì‹œì‘
uploaded_file = st.file_uploader("ğŸ“ ë¶„ì„í•  ëŒ€ìƒ PDF ì—…ë¡œë“œ", type="pdf")

if uploaded_file and links_input:
    if st.button("ğŸš€ ë“œë¼ì´ë¸Œ ë°ì´í„° ëŒ€ì¡° ì‹œì‘"):
        all_ref_problems = []
        with st.spinner('êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ê¸°ì¤€ ë¬¸í•­ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘...'):
            lines = links_input.split('\n')
            for line in lines:
                if ',' in line:
                    name, url = line.split(',', 1)
                    direct_url = get_gdrive_direct_link(url.strip())
                    try:
                        response = requests.get(direct_url)
                        if response.status_code == 200:
                            probs = extract_problems_from_bytes(response.content, name.strip())
                            all_ref_problems.extend(probs)
                    except:
                        st.error(f"{name} íŒŒì¼ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        target_problems = extract_problems_from_bytes(uploaded_file.read(), "ì—…ë¡œë“œíŒŒì¼")
        
        if all_ref_problems and target_problems:
            final_results = []
            for i, target in enumerate(target_problems):
                best_score, best_match = 0, None
                for ref in all_ref_problems:
                    score = calculate_custom_similarity(target['text'], ref['text'])
                    if score > best_score:
                        best_score, best_match = score, ref
                final_results.append({"id": i + 1, "target": target['text'], "score": best_score, "match": best_match})
            st.session_state['drive_results'] = final_results

# ê²°ê³¼ ì¶œë ¥
if 'drive_results' in st.session_state:
    for res in st.session_state['drive_results']:
        score = res['score']
        match = res['match']
        status = "ğŸ”´ ìœ„í—˜" if score > 65 else "ğŸŸ¡ ì£¼ì˜" if score > 35 else "ğŸŸ¢ ì•ˆì „"
        source = f"[{match['source']} | {match['page']}p {match['num']}]" if match else "ì—†ìŒ"
        
        with st.expander(f"{status} | {res['id']}ë²ˆ ë¬¸í•­ ({score}%) - {source}"):
            if match:
                c1, c2 = st.columns(2)
                with c1: st.markdown(f"<div class='compare-box'><b>[ì¶œì œ]</b><hr>{highlight_selective(res['target'], match['text'])}</div>", unsafe_allow_html=True)
                with c2: st.markdown(f"<div class='compare-box'><b>[DB]</b><hr>{highlight_selective(match['text'], res['target'])}</div>", unsafe_allow_html=True)